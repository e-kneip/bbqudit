{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Circuit-Level Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from bbq.polynomial import Polynomial\n",
    "from bbq.bbq_code import BivariateBicycle\n",
    "import numpy as np\n",
    "import galois\n",
    "from scipy.sparse import coo_matrix, hstack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_sm_circuit(self, x_order : list, z_order : list) -> list:\n",
    "    \"\"\"Construct one cycle of the syndrome measurement circuit for the Bivariate Bicycle code.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_order : list\n",
    "        List of integers or 'Idle' defining the order of the CNOTs for x stabilisers.\n",
    "    y_order : list\n",
    "        List of integers or 'Idle' defining the order of the CNOTs for y stabilisers.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    circ : list\n",
    "        List of gates in one cycle of the syndrome circuit: ('CNOT', control_qubit, target_qubit, power), ('Idle', qubit), ('Meas_X', qubit), ('Meas_Z', qubit), ('Prep_X', qubit), ('Prep_Z', qubit).\n",
    "    \"\"\"\n",
    "    if not isinstance(x_order, list):\n",
    "        raise TypeError(\"x_order must be a list\")\n",
    "    if not isinstance(z_order, list):\n",
    "        raise TypeError(\"y_order must be a list\")\n",
    "    for gate in x_order:\n",
    "        if not (isinstance(gate, int) or gate == 'Idle'):\n",
    "            raise TypeError(\"x_order must be an array of integers or 'Idle'\")\n",
    "    for gate in z_order:\n",
    "        if not (isinstance(gate, int) or gate == 'Idle'):\n",
    "            raise TypeError(\"z_order must be an array of integers or 'Idle'\")\n",
    "    if not x_order[0] == 'Idle':\n",
    "        raise ValueError(\"First x_order round must be 'Idle'\")\n",
    "    if not z_order[-1] == 'Idle':\n",
    "        raise ValueError(\"Last y_order round must be 'Idle'\")\n",
    "    for i in range(len(np.nonzero(self.hx[0])[0])):\n",
    "        if i not in x_order:\n",
    "            raise ValueError(\"x_order must contain all target qubits\")\n",
    "    for i in range(len(np.nonzero(self.hz[0])[0])):\n",
    "        if i not in z_order:\n",
    "            raise ValueError(\"y_order must contain all target qubits\")\n",
    "    if len(x_order) > len(z_order):\n",
    "        z_order += ['Idle'] * (len(x_order) - len(z_order))\n",
    "    elif len(z_order) > len(x_order):\n",
    "        x_order += ['Idle'] * (len(z_order) - len(x_order))\n",
    "\n",
    "    hx, hz = self.hx, self.hz\n",
    "    a, b = self.a, self.b\n",
    "    l, m, q = self.l, self.m, self.q\n",
    "    field = self.field\n",
    "    A, B = self.A, self.B\n",
    "    qubits_dict, data_qubits, x_checks, z_checks = self.qubits_dict, self.data_qubits, self.x_checks, self.z_checks\n",
    "    edges = self.edges\n",
    "\n",
    "    # Construct the circuit\n",
    "    circ = []\n",
    "    U = np.identity(4*l*m, dtype=int)  # to verify CNOT order\n",
    "\n",
    "    # For each time step, add the corresponding gate:\n",
    "    # ('CNOT', control_qubit, target_qubit, power), ('Idle', qubit), ('Meas_X', qubit), ('Meas_Y', qubit), ('Prep_X', qubit)\n",
    "\n",
    "    # Round 0: Prepare X checks, CNOT/Idle Z checks\n",
    "    t = 0\n",
    "    cnoted_data_qubits = []\n",
    "    for qubit in x_checks:\n",
    "        circ.append(('Prep_X', qubit))\n",
    "    if z_order[t] == 'Idle':\n",
    "        for qubit in z_checks:\n",
    "            circ.append(('Idle', qubit))\n",
    "    else:\n",
    "        for target in z_checks:\n",
    "            direction = z_order[t]\n",
    "            control, power = edges[(target, direction)]\n",
    "            U[qubits_dict[target], :] = (U[qubits_dict[target], :] + power * U[qubits_dict[control], :]) % field\n",
    "            cnoted_data_qubits.append(control)\n",
    "            circ.append(('CNOT', control, target, power))\n",
    "    for qubit in data_qubits:\n",
    "        if not (qubit in cnoted_data_qubits):\n",
    "            circ.append(('Idle', qubit))\n",
    "\n",
    "    # Round [1, (max-1)]: CNOT/Idle X checks, CNOT/Idle Z checks\n",
    "    for t in range(1, len(x_order)-1):\n",
    "        cnoted_data_qubits = []\n",
    "        if x_order[t] == 'Idle':\n",
    "            for qubit in x_checks:\n",
    "                circ.append(('Idle', qubit))\n",
    "        else:\n",
    "            for control in x_checks:\n",
    "                direction = x_order[t]\n",
    "                target, power = edges[(control, direction)]\n",
    "                U[qubits_dict[target], :] = (U[qubits_dict[target], :] + power * U[qubits_dict[control], :]) % field\n",
    "                cnoted_data_qubits.append(target)\n",
    "                circ.append(('CNOT', control, target, power))\n",
    "        if z_order[t] == 'Idle':\n",
    "            for qubit in z_checks:\n",
    "                circ.append(('Idle', qubit))\n",
    "        else:\n",
    "            for target in z_checks:\n",
    "                direction = z_order[t]\n",
    "                control, power = edges[(target, direction)]\n",
    "                U[qubits_dict[target], :] = (U[qubits_dict[target], :] + power * U[qubits_dict[control], :]) % field\n",
    "                cnoted_data_qubits.append(control)\n",
    "                circ.append(('CNOT', control, target, power))\n",
    "        for qubit in data_qubits:\n",
    "            if not (qubit in cnoted_data_qubits):\n",
    "                circ.append(('Idle', qubit))\n",
    "\n",
    "    # Round max: CNOT/Idle X checks, Measure Z checks\n",
    "    t = -1\n",
    "    cnoted_data_qubits = []\n",
    "    for qubit in z_checks:\n",
    "        circ.append(('Meas_Z', qubit))\n",
    "    if x_order[t] == 'Idle':\n",
    "        for qubit in x_checks:\n",
    "            circ.append(('Idle', qubit))\n",
    "    else:\n",
    "        for control in x_checks:\n",
    "            direction = x_order[t]\n",
    "            target, power = edges[(control, direction)]\n",
    "            U[qubits_dict[target], :] = (U[qubits_dict[target], :] + power * U[qubits_dict[control], :]) % field\n",
    "            circ.append(('CNOT', control, target, power))\n",
    "            cnoted_data_qubits.append(target)\n",
    "    for qubit in data_qubits:\n",
    "        if not (qubit in cnoted_data_qubits):\n",
    "            circ.append(('Idle', qubit))\n",
    "    \n",
    "    # Round final: Measure X checks, Prepare Z checks\n",
    "    for qubit in data_qubits:\n",
    "        circ.append(('Idle', qubit))\n",
    "    for qubit in x_checks:\n",
    "        circ.append(('Meas_X', qubit))\n",
    "    for qubit in z_checks:\n",
    "        circ.append(('Prep_Z', qubit))\n",
    "\n",
    "    # Test measurement circuit against max depth circuit\n",
    "    V = np.identity(4*l*m, dtype=int)\n",
    "    for t in range(len(x_order)):\n",
    "        if not x_order[t] == 'Idle':\n",
    "            for control in x_checks:\n",
    "                direction = x_order[t]\n",
    "                target, power = edges[(control, direction)]\n",
    "                V[qubits_dict[target], :] = (V[qubits_dict[target], :] + power * V[qubits_dict[control], :]) % field\n",
    "    for t in range(len(z_order)):\n",
    "        if not z_order[t] == 'Idle':\n",
    "            for target in z_checks:\n",
    "                direction = z_order[t]\n",
    "                control, power = edges[(target, direction)]\n",
    "                V[qubits_dict[target], :] = (V[qubits_dict[target], :] + power * V[qubits_dict[control], :]) % field\n",
    "    if not np.array_equal(U, V):\n",
    "        raise ValueError(\"Syndrome circuit does not match max depth syndrome circuit, check stabiliser orders\")\n",
    "\n",
    "    return circ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_decoding_matrix(self, circ : list, error_rates : dict, num_cycles : int = 1) -> np.ndarray:\n",
    "    \"\"\"Construct decoding matrix for a given syndrome circuit.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    circ : list\n",
    "        List of gates in one cycle of the syndrome circuit: ('CNOT', control_qubit, target_qubit, power), ('Idle', qubit), ('Meas_X', qubit), ('Meas_Z', qubit), ('Prep_X', qubit), ('Prep_Z', qubit).\n",
    "    error_rate : dict\n",
    "        Dictionary of error rates for keys [Meas, Prep, Idle, CNOT].\n",
    "    num_cycles : int\n",
    "        Number of cycles to repeat the syndrome circuit. Default is 1.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    hx_eff : coo_matrix\n",
    "        Decoding matrix for X stabilisers.    \n",
    "    short_hx_eff : coo_matrix\n",
    "        Decoding matrix for X stabilisers without columns for logicals.    \n",
    "    hz_eff : coo_matrix\n",
    "        Decoding matrix for Z stabilisers.    \n",
    "    short_hz_eff : coo_matrix\n",
    "        Decoding matrix for Z stabilisers without columns for logicals.\n",
    "    channel_prob_x : list\n",
    "        List of probabilities for each X syndrome, i.e. each column in hx_eff.    \n",
    "    channel_prob_z : list\n",
    "        List of probabilities for each Z syndrome, i.e. each column in hz_eff.\n",
    "    \"\"\"\n",
    "    if not (isinstance(error_rates, dict)):\n",
    "        raise TypeError(\"error_rates must be a dictionary\")\n",
    "    for key in error_rates.keys():\n",
    "        if (key not in ['Meas', 'Prep', 'Idle', 'CNOT']) or (len(error_rates) != 4):\n",
    "            raise ValueError(\"error_rates must have keys ['Meas', 'Prep', 'Idle', 'CNOT']\")\n",
    "        if not (isinstance(error_rates[key], float) and 0 <= error_rates[key] <= 1):\n",
    "            raise ValueError(\"error_rates must have values between 0 and 1\")\n",
    "    if not (isinstance(num_cycles, int) and num_cycles > 0):\n",
    "        raise TypeError(\"num_cycles must be a positive integer\")\n",
    "\n",
    "    l, m = self.l, self.m\n",
    "    field = self.field\n",
    "    qubits_dict, data_qubits = self.qubits_dict, self.data_qubits\n",
    "    x_logicals, z_logicals = self.x_logicals, self.z_logicals\n",
    "    x_checks, z_checks = self.x_checks, self.z_checks\n",
    "\n",
    "    # Construct repeated circuit\n",
    "    repeated_circ = circ * num_cycles\n",
    "\n",
    "    # Single error circuits\n",
    "    z_prob, z_circuit = [], []\n",
    "    x_prob, x_circuit = [], []\n",
    "    head = []\n",
    "    tail = repeated_circ.copy()\n",
    "    for gate in repeated_circ:\n",
    "        # assert gate[0] in ['CNOT', 'Idle', 'Meas_X', 'Meas_Z', 'Prep_X', 'Prep_Z']\n",
    "        if gate[0] == 'Meas_X':\n",
    "            # Meas_X error only affects Z detectors\n",
    "            z_circuit.append(head + [('Z', gate[1])] + tail)\n",
    "            z_prob.append(error_rates['Meas'])\n",
    "        if gate[0] == 'Meas_Z':\n",
    "            # Meas_Z error only affects X detectors\n",
    "            x_circuit.append(head + [('X', gate[1])] + tail)\n",
    "            x_prob.append(error_rates['Meas'])\n",
    "        head.append(gate)\n",
    "        tail.pop(0)\n",
    "        # assert repeated_circ == head + tail\n",
    "        if gate[0] == 'Prep_X':\n",
    "            # Prep_X error only affects Z detectors\n",
    "            z_circuit.append(head + [('Z', gate[1])] + tail)\n",
    "            z_prob.append(error_rates['Prep'])\n",
    "        if gate[0] == 'Prep_Z':\n",
    "            # Prep_Z error only affects X detectors\n",
    "            x_circuit.append(head + [('X', gate[1])] + tail)\n",
    "            x_prob.append(error_rates['Prep'])\n",
    "        if gate[0] == 'Idle':\n",
    "            # Idle error on Z detectors\n",
    "            z_circuit.append(head + [('Z', gate[1])] + tail)\n",
    "            z_prob.append(error_rates['Idle']*2/3)  # 3 possible Idle errors are X, Y, Z so Z is 2/3 (Y and Z)\n",
    "            # Idle error on X detectors\n",
    "            x_circuit.append(head + [('X', gate[1])] + tail)\n",
    "            x_prob.append(error_rates['Idle']*2/3)\n",
    "        if gate[0] == 'CNOT':\n",
    "            # Z error on control\n",
    "            z_circuit.append(head + [('Z', gate[1])] + tail)\n",
    "            z_prob.append(error_rates['CNOT']*4/15)  # possible CNOT errors are IX, IY, ..., ZZ so Z is 4/15 (IZ, IY, XZ and XY)\n",
    "            # Z error on target\n",
    "            z_circuit.append(head + [('Z', gate[2])] + tail)\n",
    "            z_prob.append(error_rates['CNOT']*4/15)\n",
    "            # Z error on both\n",
    "            z_circuit.append(head + [('ZZ', gate[1], gate[2])] + tail)\n",
    "            z_prob.append(error_rates['CNOT']*4/15)\n",
    "            # X error on control\n",
    "            x_circuit.append(head + [('X', gate[1])] + tail)\n",
    "            x_prob.append(error_rates['CNOT']*4/15)\n",
    "            # X error on target\n",
    "            x_circuit.append(head + [('X', gate[2])] + tail)\n",
    "            x_prob.append(error_rates['CNOT']*4/15)\n",
    "            # X error on both\n",
    "            x_circuit.append(head + [('XX', gate[1], gate[2])] + tail)\n",
    "            x_prob.append(error_rates['CNOT']*4/15)\n",
    "\n",
    "    # Execute each noisy X circuit and compute syndrome\n",
    "    # Add two noiseless syndrome cycles to end\n",
    "    cnt = 0\n",
    "    Hx_dict = {}\n",
    "    for x_circ in x_circuit:\n",
    "        syndrome_history, state, syndrome_map, err_cnt = self._simulate_x_circuit(x_circ + circ + circ)\n",
    "        assert err_cnt == 1\n",
    "        assert len(syndrome_history) == l * m * (num_cycles + 2)\n",
    "\n",
    "        # Compute final state of data qubits and logical effect\n",
    "        state_data_qubits = [state[qubits_dict[qubit]] for qubit in data_qubits]\n",
    "        syndrome_final_logical = (np.array(z_logicals) @ state_data_qubits) % field\n",
    "\n",
    "        # Syndrome sparsification, i.e. only keep syndrome entries that change from previous cycle\n",
    "        syndrome_history_copy = syndrome_history.copy()\n",
    "        for check in z_checks:\n",
    "            pos = syndrome_map[check]\n",
    "            assert len(pos) == num_cycles + 2\n",
    "            for row in range(1, num_cycles + 2):\n",
    "                syndrome_history[pos[row]] += syndrome_history_copy[pos[row-1]]\n",
    "        syndrome_history %= field\n",
    "\n",
    "        # Combine syndrome_history and syndrome_final_logical\n",
    "        syndrome_history_augmented = np.hstack([syndrome_history, syndrome_final_logical])\n",
    "\n",
    "        # Hx_dict maps flagged Z stabilisers to corresponding noisy circuit, i.e. Hx_dict[flagged_z_stab] = [noisy_circuit_1, noisy_circuit_2, ...]\n",
    "        supp = tuple(np.nonzero(syndrome_history_augmented)[0])\n",
    "        if supp in Hx_dict:\n",
    "            Hx_dict[supp].append(cnt)\n",
    "        else:\n",
    "            Hx_dict[supp] = [cnt]\n",
    "        cnt += 1\n",
    "\n",
    "    first_logical_row_x = l * m * (num_cycles + 2)\n",
    "    num_x_errors = len(Hx_dict)  # Number of distinct X syndrome histories\n",
    "    k = len(x_logicals) # Number of logical qubits\n",
    "    hx_eff, short_hx_eff = [], []\n",
    "    channel_prob_x = []\n",
    "    for supp in Hx_dict:\n",
    "        new_col = np.zeros((l * m * (num_cycles + 2) + k, 1), dtype=int)  # With the augmented part for logicals\n",
    "        new_col_short = np.zeros((l * m * (num_cycles + 2), 1), dtype=int)\n",
    "        new_col[list(supp), 0] = 1  # 1 indicates which stabiliser is flagged\n",
    "        new_col_short[:, 0] = new_col[0:first_logical_row_x, 0]\n",
    "        hx_eff.append(coo_matrix(new_col))\n",
    "        short_hx_eff.append(coo_matrix(new_col_short))\n",
    "        channel_prob_x.append(np.sum([x_prob[i] for i in Hx_dict[supp]]))  # Probability of a given x syndrome\n",
    "    hx_eff = hstack(hx_eff)  # Column = error mechanism, row = flagged stabilisers\n",
    "    short_hx_eff = hstack(short_hx_eff)  # Shortened hx_eff without columns for logicals\n",
    "\n",
    "    # Execute each noisy Z circuit and compute syndrome\n",
    "    # Add two noiseless syndrome cycles to end\n",
    "    cnt = 0\n",
    "    Hz_dict = {}\n",
    "    for z_circ in z_circuit:\n",
    "        syndrome_history, state, syndrome_map, err_cnt = self._simulate_z_circuit(z_circ + circ + circ)\n",
    "        assert err_cnt == 1\n",
    "        assert len(syndrome_history) == l * m * (num_cycles + 2)\n",
    "\n",
    "        # Compute final state of data qubits and logical effect\n",
    "        state_data_qubits = [state[qubits_dict[qubit]] for qubit in data_qubits]\n",
    "        syndrome_final_logical = (np.array(x_logicals) @ state_data_qubits) % field\n",
    "\n",
    "        # Syndrome sparsification, i.e. only keep syndrome entries that change from previous cycle\n",
    "        syndrome_history_copy = syndrome_history.copy()\n",
    "        for check in x_checks:\n",
    "            pos = syndrome_map[check]\n",
    "            assert len(pos) == num_cycles + 2\n",
    "            for row in range(1, num_cycles + 2):\n",
    "                syndrome_history[pos[row]] += syndrome_history_copy[pos[row-1]]\n",
    "        syndrome_history %= field\n",
    "\n",
    "        # Combine syndrome_history and syndrome_final_logical\n",
    "        syndrome_history_augmented = np.hstack([syndrome_history, syndrome_final_logical])\n",
    "\n",
    "        # Hz_dict maps flagged X stabilisers to corresponding noisy circuit, i.e. Hz_dict[flagged_x_stab] = [noisy_circuit_1, noisy_circuit_2, ...]\n",
    "        supp = tuple(np.nonzero(syndrome_history_augmented)[0])\n",
    "        if supp in Hz_dict:\n",
    "            Hz_dict[supp].append(cnt)\n",
    "        else:\n",
    "            Hz_dict[supp] = [cnt]\n",
    "        cnt += 1\n",
    "\n",
    "    first_logical_row_z = l * m * (num_cycles + 2)\n",
    "    num_z_errors = len(Hz_dict)  # Number of distinct Z syndrome histories\n",
    "    hz_eff, short_hz_eff = [], []\n",
    "    channel_prob_z = []\n",
    "    for supp in Hz_dict:\n",
    "        new_col = np.zeros((l * m * (num_cycles + 2) + k, 1), dtype=int)  # With the augmented part for logicals\n",
    "        new_col_short = np.zeros((l * m * (num_cycles + 2), 1), dtype=int)\n",
    "        new_col[list(supp), 0] = 1  # 1 indicates which stabiliser is flagged\n",
    "        new_col_short[:, 0] = new_col[0:first_logical_row_z, 0]\n",
    "        hz_eff.append(coo_matrix(new_col))\n",
    "        short_hz_eff.append(coo_matrix(new_col_short))\n",
    "        channel_prob_z.append(np.sum([z_prob[i] for i in Hz_dict[supp]]))  # Probability of a given z syndrome\n",
    "    hz_eff = hstack(hz_eff)  # Row = flagged stabilisers, column = noisy circuit\n",
    "    short_hz_eff = hstack(short_hz_eff)  # Shortened hz_eff without columns for logicals\n",
    "\n",
    "    return hx_eff, short_hx_eff, hz_eff, short_hz_eff, channel_prob_x, channel_prob_z, x_circuit, z_circuit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rref_with_pivots(A, v, x = None):\n",
    "    \"\"\"\n",
    "    Perform Gaussian elimination to find the reduced row echelon form (RREF).\n",
    "    Also identifies the pivot columns.\n",
    "    Also reduces a vector to keep a linear system invariant.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : Galois field array\n",
    "        Galois field matrix to row reduce\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    A_rref : Galois field array\n",
    "        Row-reduced form of A\n",
    "    pivots : list\n",
    "        Indices of pivot columns\n",
    "    \"\"\"\n",
    "    # Get a copy to avoid modifying the original\n",
    "    A_rref = A.copy()\n",
    "    v_rref = v.copy()\n",
    "    m, n = A_rref.shape\n",
    "    assert v.shape == (m,)\n",
    "    # assert (A_rref @ x == v_rref).all()\n",
    "    \n",
    "    # Track the pivot positions\n",
    "    pivot_cols = []\n",
    "    pivot_rows = []\n",
    "    \n",
    "    # Iterate through columns\n",
    "    for c in range(n):\n",
    "        # Find pivot in column c\n",
    "        for r in range(m):\n",
    "            if A_rref[r, c] != 0 and r not in pivot_rows:\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Record this column as a pivot column\n",
    "        pivot_cols.append(c)\n",
    "        pivot_rows.append(r)\n",
    "        \n",
    "        # Scale the pivot row to make the pivot element 1\n",
    "        pivot = A_rref[r, c]\n",
    "        A_rref[r] = A_rref[r] / pivot\n",
    "        v_rref[r] = v_rref[r] / pivot\n",
    "        \n",
    "        # Eliminate other elements in the pivot column\n",
    "        for i in range(m):\n",
    "            if i != r and A_rref[i, c] != 0:\n",
    "                v_rref[i] = v_rref[i] - A_rref[i,c] * v_rref[r]\n",
    "                A_rref[i] = A_rref[i] - A_rref[i, c] * A_rref[r]\n",
    "        \n",
    "        # If we've exhausted all rows, we're done\n",
    "        if len(pivot_rows) == m:\n",
    "            break\n",
    "    \n",
    "    # if len(pivot_rows) < A.shape[0]:\n",
    "    #     print(\"Matrix is not full rank.\")\n",
    "\n",
    "    return A_rref[sorted(pivot_rows)], v_rref[sorted(pivot_rows)], pivot_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dijkstra_osd_decode(self, syndrome_history, prior, h_eff, debug = False):\n",
    "    \"\"\"Decode the syndrome using D+OSD.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    syndrome_history : nd.array\n",
    "        The syndrome of the error.\n",
    "    prior : nd.array\n",
    "        The probability of each error mechanism.\n",
    "    h_eff : nd.array\n",
    "        The effective parity check matrix, where columns = error mechanism and rows = syndrome (flagged stabilisers).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    error : nd.array\n",
    "        The estimated error.\n",
    "    \"\"\"\n",
    "    if not isinstance(syndrome_history, np.ndarray):\n",
    "        raise TypeError('syndrome must be a numpy array')\n",
    "    if not isinstance(prior, np.ndarray):\n",
    "        raise TypeError('prior must be a np.ndarray')\n",
    "\n",
    "    field = self.field\n",
    "    qubits_dict = self.qubits_dict\n",
    "    data_qubits, x_checks, z_checks = self.data_qubits, self.x_checks, self.z_checks\n",
    "\n",
    "    m, n = h_eff.shape\n",
    "\n",
    "    # Mini-Dijkstra\n",
    "    check_distances = np.ones(m) * n\n",
    "    error_distances = np.ones(n) * n\n",
    "\n",
    "    # Set the distance each detector is from an error\n",
    "    for c in syndrome_history.nonzero()[0]:\n",
    "        check_distances[c] = 0\n",
    "\n",
    "    update_made = True\n",
    "    while update_made:\n",
    "        update_made = False\n",
    "        for c in range(m):\n",
    "            current_distance = check_distances[c]\n",
    "            for e in np.nonzero(h_eff[c])[0]:\n",
    "                if current_distance + 1 < error_distances[e]:\n",
    "                    error_distances[e] = current_distance + 1\n",
    "                    update_made = True\n",
    "\n",
    "        for e in range(n):\n",
    "            current_distance = error_distances[e]\n",
    "            for c in np.nonzero(h_eff[:,e])[0]:\n",
    "                if current_distance + 1 < check_distances[c]:\n",
    "                    check_distances[c] = current_distance + 1\n",
    "                    update_made = True\n",
    "\n",
    "    certainties = error_distances\n",
    "\n",
    "    # Sort errors by how certain we are of their values (most to least)\n",
    "    col_rank_perm = np.argsort(certainties)\n",
    "    col_rank_inv_perm = np.empty_like(col_rank_perm)\n",
    "    col_rank_inv_perm[col_rank_perm] = np.arange(len(col_rank_perm))\n",
    "\n",
    "    # Create Galois field elements\n",
    "    GF = galois.GF(field)\n",
    "\n",
    "    # Convert H and syndrome to Galois field arrays\n",
    "    H_gf = GF(h_eff.copy())\n",
    "    syndrome_gf = GF(syndrome_history.copy())\n",
    "    \n",
    "    # Order the columns of h_gf and prior according to the ranking\n",
    "    H_ordered_gf = H_gf[:, col_rank_perm]\n",
    "    priors_perm = prior[col_rank_perm]\n",
    "\n",
    "    # Find the reduced row echelon form (RREF) and identify pivot columns\n",
    "    H_rref_gf, syndrome_rref_gf, pivot_cols = rref_with_pivots(H_ordered_gf, syndrome_gf)\n",
    "    m_ind = H_rref_gf.shape[0]\n",
    "    non_pivot_cols = [i for i in range(n) if i not in pivot_cols]\n",
    "\n",
    "    # Select the first rank(h_gf) linearly independent columns as basis set in P, others in B\n",
    "    P = H_rref_gf[:, pivot_cols]\n",
    "    assert P.shape == (m_ind, m_ind)\n",
    "    B = H_rref_gf[:, non_pivot_cols]\n",
    "\n",
    "    def sln_from(g):\n",
    "        assert g.shape == (n - m_ind,)\n",
    "        remainder =  syndrome_rref_gf - B @ g\n",
    "        fix = np.linalg.solve(P, remainder)\n",
    "        assert (P @ fix + B @ g == syndrome_rref_gf).all()\n",
    "\n",
    "        score = 0\n",
    "        sln = GF.Zeros(n)\n",
    "        # Find prob of basis set\n",
    "        for i in range(m_ind):\n",
    "            p = priors_perm[pivot_cols[i], fix[i]]\n",
    "            sln[pivot_cols[i]] = fix[i]\n",
    "            if p > 0:\n",
    "                score += np.log(p)\n",
    "            else:\n",
    "                score -= 1000\n",
    "        \n",
    "        for i in range(n - m_ind):\n",
    "            p = priors_perm[non_pivot_cols[i], g[i]]\n",
    "            sln[non_pivot_cols[i]] = g[i]\n",
    "            if p > 0:\n",
    "                score += np.log(p)\n",
    "            else:\n",
    "                score -= 1000\n",
    "\n",
    "        # Check sln makes correct syndrome\n",
    "        assert (H_rref_gf @ sln == syndrome_rref_gf).all()\n",
    "        assert (H_gf @ sln[col_rank_inv_perm] == syndrome_gf).all()\n",
    "\n",
    "        assert ((h_eff @ sln[col_rank_inv_perm].__array__()) % field == syndrome_history).all()\n",
    "\n",
    "        return np.array(sln[col_rank_inv_perm]), score\n",
    "\n",
    "    # OSD_0 solution\n",
    "    best_solution, best_score = sln_from(GF.Zeros(n - m_ind))\n",
    "    assert ((h_eff @ best_solution) % field == syndrome_history).all()\n",
    "    pivot_col_labels = {col_rank_perm[c]: int(error_distances[col_rank_perm[c]]) for c in pivot_cols}\n",
    "\n",
    "    # print(f'for debugging: {best_solution}, {True}, {[col_rank_perm[i] for i in pivot_cols]}, {pivot_col_labels}')\n",
    "\n",
    "    return best_solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(self, iterations, circ, error_rates, num_cycles, hx_eff, short_hx_eff, hz_eff, short_hz_eff, channel_prob_x, channel_prob_z, verbose=False):\n",
    "    \"\"\"Simulate the code for given iterations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    iterations : int\n",
    "        The number of iterations of the simulation.\n",
    "    circ : list\n",
    "        The syndrome measurement circuit.\n",
    "    error_rates : dict\n",
    "        Dictionary with error rates with keys ['Meas', 'Prep', 'Idle', 'CNOT'].\n",
    "    num_cycles : int\n",
    "        Number of cycles to repeat the syndrome circuit.\n",
    "    hx_eff : nd.array\n",
    "        The effective X parity check matrix.\n",
    "    short_hx_eff : nd.array\n",
    "        The effective X parity check matrix without logicals.\n",
    "    hz_eff : nd.array\n",
    "        The effective Z parity check matrix.\n",
    "    short_hz_eff : nd.array\n",
    "        The effective Z parity check matrix without logicals.\n",
    "    channel_prob_x : list\n",
    "        The probability of each X error mechanism.\n",
    "    channel_prob_z : list\n",
    "        The probability of each Z error mechanism.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Logical error rate.\n",
    "    \"\"\"\n",
    "    field = self.field\n",
    "    l, m = self.l, self.m\n",
    "    qubits_dict = self.qubits_dict\n",
    "    data_qubits = self.data_qubits\n",
    "    x_checks, z_checks = self.x_checks, self.z_checks\n",
    "    x_logicals, z_logicals = self.x_logicals, self.z_logicals\n",
    "    hx_eff, hz_eff = hx_eff.toarray(), hz_eff.toarray()\n",
    "    short_hx_eff, short_hz_eff = short_hx_eff.toarray(), short_hz_eff.toarray()\n",
    "    first_logical_row = l * m * (num_cycles + 2)\n",
    "    k = len(x_logicals)\n",
    "\n",
    "    # Set up priors\n",
    "    x_prior = np.zeros((len(channel_prob_x), field), dtype=float)\n",
    "    z_prior = np.zeros((len(channel_prob_z), field), dtype=float)\n",
    "\n",
    "    for i, prob in enumerate(channel_prob_x):\n",
    "        x_prior[i, 0] = 1 - prob\n",
    "        for j in range(1, field):\n",
    "            x_prior[i, j] = prob / (field - 1)\n",
    "    for i, prob in enumerate(channel_prob_z):\n",
    "        z_prior[i, 0] = 1 - prob\n",
    "        for j in range(1, field):\n",
    "            z_prior[i, j] = prob / (field - 1)\n",
    "\n",
    "    # Run for given number of iterations\n",
    "    success_count = 0\n",
    "    for _ in range(iterations):\n",
    "\n",
    "        # Generate noisy circuit\n",
    "        noisy_circ, err_cnt = self._generate_noisy_circuit(circ * num_cycles, error_rates)\n",
    "        if verbose:\n",
    "            print(f'Number of errors: {err_cnt}')\n",
    "\n",
    "        # Run X decoding and Z decosing sequentially\n",
    "        x_success, z_success = False, False\n",
    "\n",
    "        # Correct X errors\n",
    "        x_syndrome_history, x_state, x_syndrome_map, x_err_count = self._simulate_x_circuit(noisy_circ + circ + circ)\n",
    "        if verbose:\n",
    "            print(f'Number of X errors: {x_err_count}')\n",
    "            print(f'x_syndrome_history: {x_syndrome_history}')\n",
    "        x_state_data_qubits = [x_state[qubits_dict[qubit]] for qubit in data_qubits]\n",
    "        x_syndrome_final_logical = (np.array(z_logicals) @ x_state_data_qubits) % field\n",
    "        # Syndrome sparsification\n",
    "        x_syndrome_history_copy = x_syndrome_history.copy()\n",
    "        for check in z_checks:\n",
    "            pos = x_syndrome_map[check]\n",
    "            assert len(pos) == num_cycles + 2\n",
    "            for row in range(1, num_cycles + 2):\n",
    "                x_syndrome_history[pos[row]] += x_syndrome_history_copy[pos[row-1]]\n",
    "        x_syndrome_history %= field\n",
    "        x_error = dijkstra_osd_decode(self, x_syndrome_history, x_prior, short_hx_eff)\n",
    "\n",
    "        assert np.all((short_hx_eff @ x_error) % field == x_syndrome_history)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'x_error: {x_error}')\n",
    "            print(f'short_hx_eff @ x_error == syndrome: {((short_hx_eff @ x_error) % field == x_syndrome_history).all()}')\n",
    "\n",
    "        # Check logical effect\n",
    "        x_syndrome_history_augmented_guessed = (hx_eff @ x_error) % field\n",
    "        x_syndrome_final_logical_guessed = x_syndrome_history_augmented_guessed[first_logical_row: first_logical_row + k]\n",
    "        if verbose:\n",
    "            print(f'{x_syndrome_final_logical_guessed=}')\n",
    "            print(f'{x_syndrome_final_logical=}')\n",
    "        x_success = np.array_equal(x_syndrome_final_logical_guessed, x_syndrome_final_logical)\n",
    "\n",
    "        # Correct Z errors\n",
    "#        if x_success:\n",
    "#            z_syndrome_history, z_state, z_syndrome_map, z_err_count = self._simulate_z_circuit(noisy_circ + circ + circ)\n",
    "#            # print(f'z_syndrome_history: {z_syndrome_history}')\n",
    "#            z_state_data_qubits = [z_state[qubits_dict[qubit]] for qubit in data_qubits]\n",
    "#            z_syndrome_final_logical = (np.array(x_logicals) @ z_state_data_qubits) % field\n",
    "#            # Syndrome sparsification\n",
    "#            z_syndrome_history_copy = z_syndrome_history.copy()\n",
    "#            for check in x_checks:\n",
    "#                pos = z_syndrome_map[check]\n",
    "#                assert len(pos) == num_cycles + 2\n",
    "#                for row in range(1, num_cycles + 2):\n",
    "#                    z_syndrome_history[pos[row]] += z_syndrome_history_copy[pos[row-1]]\n",
    "#            z_syndrome_history %= field\n",
    "#            z_error = dijkstra_osd_decode(self, z_syndrome_history, z_prior, short_hz_eff)\n",
    "\n",
    "            # Check logical effect\n",
    "#            z_syndrome_history_augmented_guessed = (hz_eff @ z_error) % field\n",
    "#            z_syndrome_final_logical_guessed = z_syndrome_history_augmented_guessed[first_logical_row: first_logical_row + k]\n",
    "#            z_success = np.array_equal(z_syndrome_final_logical_guessed, z_syndrome_final_logical)\n",
    "        z_success = True\n",
    "\n",
    "        # Check if the decoding was successful\n",
    "        success = x_success and z_success\n",
    "\n",
    "        if success:\n",
    "            success_count += 1\n",
    "\n",
    "    return 1 - (success_count / iterations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(self, iterations, circ, error_rates, num_cycles, hx_eff, short_hx_eff, hz_eff, short_hz_eff, channel_prob_x, channel_prob_z, max_iter, verbose=False):\n",
    "    \"\"\"Simulate the code for given iterations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    iterations : int\n",
    "        The number of iterations of the simulation.\n",
    "    circ : list\n",
    "        The syndrome measurement circuit.\n",
    "    error_rates : dict\n",
    "        Dictionary with error rates with keys ['Meas', 'Prep', 'Idle', 'CNOT'].\n",
    "    num_cycles : int\n",
    "        Number of cycles to repeat the syndrome circuit.\n",
    "    hx_eff : nd.array\n",
    "        The effective X parity check matrix.\n",
    "    short_hx_eff : nd.array\n",
    "        The effective X parity check matrix without logicals.\n",
    "    hz_eff : nd.array\n",
    "        The effective Z parity check matrix.\n",
    "    short_hz_eff : nd.array\n",
    "        The effective Z parity check matrix without logicals.\n",
    "    channel_prob_x : list\n",
    "        The probability of each X error mechanism.\n",
    "    channel_prob_z : list\n",
    "        The probability of each Z error mechanism.\n",
    "    max_iter : int\n",
    "        Number of max iterations for the BP decoder.\n",
    "    verbose : bool\n",
    "        If True, print debugging information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Logical error rate.\n",
    "    \"\"\"\n",
    "    field = self.field\n",
    "    l, m = self.l, self.m\n",
    "    qubits_dict = self.qubits_dict\n",
    "    data_qubits = self.data_qubits\n",
    "    x_checks, z_checks = self.x_checks, self.z_checks\n",
    "    x_logicals, z_logicals = self.x_logicals, self.z_logicals\n",
    "    hx_eff, hz_eff = hx_eff.toarray(), hz_eff.toarray()\n",
    "    short_hx_eff, short_hz_eff = short_hx_eff.toarray(), short_hz_eff.toarray()\n",
    "    first_logical_row = l * m * (num_cycles + 2)\n",
    "    k = len(x_logicals)\n",
    "\n",
    "    # Set up priors\n",
    "    x_prior = np.zeros((len(channel_prob_x), field), dtype=float)\n",
    "    z_prior = np.zeros((len(channel_prob_z), field), dtype=float)\n",
    "\n",
    "    for i, prob in enumerate(channel_prob_x):\n",
    "        x_prior[i, 0] = 1 - prob\n",
    "        for j in range(1, field):\n",
    "            x_prior[i, j] = prob / (field - 1)\n",
    "    for i, prob in enumerate(channel_prob_z):\n",
    "        z_prior[i, 0] = 1 - prob\n",
    "        for j in range(1, field):\n",
    "            z_prior[i, j] = prob / (field - 1)\n",
    "\n",
    "    # Run for given number of iterations\n",
    "    success_count = 0\n",
    "    for _ in range(iterations):\n",
    "\n",
    "        # Generate noisy circuit\n",
    "        noisy_circ, err_cnt = self._generate_noisy_circuit(circ * num_cycles, error_rates)\n",
    "        if verbose:\n",
    "            print(f'Number of errors: {err_cnt}')\n",
    "\n",
    "        # Run X decoding and Z decosing sequentially\n",
    "        x_success, z_success = False, False\n",
    "\n",
    "        # Correct X errors\n",
    "        x_syndrome_history, x_state, x_syndrome_map, x_err_count = self._simulate_x_circuit(noisy_circ + circ + circ)\n",
    "        if verbose:\n",
    "            print(f'Number of X errors: {x_err_count}')\n",
    "            print(f'x_syndrome_history: {x_syndrome_history}')\n",
    "        x_state_data_qubits = [x_state[qubits_dict[qubit]] for qubit in data_qubits]\n",
    "        x_syndrome_final_logical = (np.array(z_logicals) @ x_state_data_qubits) % field\n",
    "        # Syndrome sparsification\n",
    "        x_syndrome_history_copy = x_syndrome_history.copy()\n",
    "        for check in z_checks:\n",
    "            pos = x_syndrome_map[check]\n",
    "            assert len(pos) == num_cycles + 2\n",
    "            for row in range(1, num_cycles + 2):\n",
    "                x_syndrome_history[pos[row]] += x_syndrome_history_copy[pos[row-1]]\n",
    "        x_syndrome_history %= field\n",
    "        x_error, x_decoding_success = bp_osd_decode(self, x_syndrome_history, x_prior, short_hx_eff, max_iter)\n",
    "\n",
    "        if not x_decoding_success:\n",
    "            return 'Failed to decode :('\n",
    "\n",
    "        if verbose:\n",
    "            print(f'x_error: {x_error}')\n",
    "            print(f'short_hx_eff @ x_error == syndrome: {((short_hx_eff @ x_error) % field == x_syndrome_history).all()}')\n",
    "\n",
    "        assert np.all((short_hx_eff @ x_error) % field == x_syndrome_history)\n",
    "\n",
    "        # Check logical effect\n",
    "        x_syndrome_history_augmented_guessed = (hx_eff @ x_error) % field\n",
    "        x_syndrome_final_logical_guessed = x_syndrome_history_augmented_guessed[first_logical_row: first_logical_row + k]\n",
    "        if verbose:\n",
    "            print(f'{x_syndrome_final_logical_guessed=}')\n",
    "            print(f'{x_syndrome_final_logical=}')\n",
    "        x_success = np.array_equal(x_syndrome_final_logical_guessed, x_syndrome_final_logical)\n",
    "\n",
    "        # Correct Z errors\n",
    "#        if x_success:\n",
    "#            z_syndrome_history, z_state, z_syndrome_map, z_err_count = self._simulate_z_circuit(noisy_circ + circ + circ)\n",
    "#            # print(f'z_syndrome_history: {z_syndrome_history}')\n",
    "#            z_state_data_qubits = [z_state[qubits_dict[qubit]] for qubit in data_qubits]\n",
    "#            z_syndrome_final_logical = (np.array(x_logicals) @ z_state_data_qubits) % field\n",
    "#            # Syndrome sparsification\n",
    "#            z_syndrome_history_copy = z_syndrome_history.copy()\n",
    "#            for check in x_checks:\n",
    "#                pos = z_syndrome_map[check]\n",
    "#                assert len(pos) == num_cycles + 2\n",
    "#                for row in range(1, num_cycles + 2):\n",
    "#                    z_syndrome_history[pos[row]] += z_syndrome_history_copy[pos[row-1]]\n",
    "#            z_syndrome_history %= field\n",
    "#            z_error = dijkstra_osd_decode(self, z_syndrome_history, z_prior, short_hz_eff)\n",
    "\n",
    "            # Check logical effect\n",
    "#            z_syndrome_history_augmented_guessed = (hz_eff @ z_error) % field\n",
    "#            z_syndrome_final_logical_guessed = z_syndrome_history_augmented_guessed[first_logical_row: first_logical_row + k]\n",
    "#            z_success = np.array_equal(z_syndrome_final_logical_guessed, z_syndrome_final_logical)\n",
    "        z_success = True\n",
    "\n",
    "        # Check if the decoding was successful\n",
    "        success = x_success and z_success\n",
    "\n",
    "        if success:\n",
    "            success_count += 1\n",
    "\n",
    "    return 1 - (success_count / iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _err_to_det(h_eff):\n",
    "    \"\"\"Find the detectors in the neighbourhood of each error, i.e. error : [neighbouring detectors].\"\"\"\n",
    "    det, err = np.nonzero(h_eff)\n",
    "    err_neighbourhood = {}\n",
    "    for i in range(len(err)):\n",
    "        if err[i] not in err_neighbourhood:\n",
    "            err_neighbourhood[int(err[i])] = [int(det[i])]\n",
    "        else:\n",
    "            err_neighbourhood[int(err[i])].append(int(det[i]))\n",
    "    return err_neighbourhood\n",
    "\n",
    "def _det_to_err(h_eff):\n",
    "    \"\"\"Find the errors in the neighbourhood of each detector, i.e. detector : [neighbouring errors].\"\"\"\n",
    "    det, err = np.nonzero(h_eff)\n",
    "    det_neighourhood = {}\n",
    "    for i in range(len(det)):\n",
    "        if det[i] not in det_neighourhood:\n",
    "            det_neighourhood[int(det[i])] = [int(err[i])]\n",
    "        else:\n",
    "            det_neighourhood[int(det[i])].append(int(err[i]))\n",
    "    return det_neighourhood\n",
    "\n",
    "def bp_osd_decode(self, syndrome, prior, h_eff, max_iter, bp_only=False):\n",
    "    \"\"\"Decode the syndrome using BP+OSD.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    syndrome : nd.array\n",
    "        The syndrome of the error.\n",
    "    prior : nd.array\n",
    "        The probability of each error mechanism.\n",
    "    h_eff : nd.array\n",
    "        The effective parity check matrix, where columns = error mechanism and rows = syndrome (flagged stabilisers).\n",
    "    max_iter : int\n",
    "        The maximum number of iterations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    error : nd.array\n",
    "        The error.\n",
    "    success : bool\n",
    "        Whether the decoding was successful.\n",
    "    \"\"\"\n",
    "    if not isinstance(syndrome, np.ndarray):\n",
    "        raise TypeError('syndrome must be a numpy array')\n",
    "    if not isinstance(prior, np.ndarray):\n",
    "        raise TypeError('prior must be a numpy array')\n",
    "    if not (isinstance(max_iter, int) and max_iter > 0):\n",
    "        raise ValueError('max_iter must be a positive integer')\n",
    "\n",
    "    field = self.field\n",
    "    qubits_dict = self.qubits_dict\n",
    "    data_qubits, x_checks, z_checks = self.data_qubits, self.x_checks, self.z_checks\n",
    "    n_detectors, n_errors = h_eff.shape\n",
    "\n",
    "    err_neighbourhood = _err_to_det(h_eff)\n",
    "    det_neighbourhood = _det_to_err(h_eff)\n",
    "\n",
    "    # ------------------------BP--------------------------------\n",
    "\n",
    "    # Step 0: initialisation\n",
    "    # Q[k, i] is the message passed from error k to check i\n",
    "    Q = np.zeros((n_errors, n_detectors, field))\n",
    "    for i in range(n_errors):\n",
    "        # Send the same message of priors for each error to its neighbouring detectors\n",
    "    \n",
    "        #######################################################################\n",
    "        # WARNING: If an error flags no detectors, sets messages to 0, => if syndrome is all 0, then will always say 0 errors (not a possible non-0 solution) *I think*\n",
    "        #######################################################################\n",
    "    \n",
    "        if i in err_neighbourhood:\n",
    "            dets = err_neighbourhood[i]\n",
    "            Q[i, dets, :] = prior[i]\n",
    "    # P[i, k] is the message passed from check i to error k\n",
    "    P = np.zeros((n_detectors, n_errors, field))\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        posteriors = np.zeros(prior.shape)\n",
    "\n",
    "        # Step 1: pass check to error messages\n",
    "\n",
    "        for i in det_neighbourhood:\n",
    "            errs = det_neighbourhood[i]\n",
    "\n",
    "            # Isolate the relevant error messages\n",
    "            convolution = Q[errs, i, :].copy()\n",
    "\n",
    "            # Fourier transform the error messages\n",
    "            convolution = np.fft.fft(convolution, axis=1)\n",
    "\n",
    "            for j in range(len(errs)):\n",
    "                # Remove the j-th error message from the convolution\n",
    "                sub_convolution = np.delete(convolution, j, axis=0)\n",
    "\n",
    "                # Compute the product of the transformed error messages\n",
    "                sub_convolution = np.prod(sub_convolution, axis=0)\n",
    "\n",
    "                # Inverse Fourier transform the product to find the convolution\n",
    "                sub_convolution = np.fft.ifft(sub_convolution, axis=0)\n",
    "\n",
    "                # Pass message\n",
    "                for k in range(field):\n",
    "                    P[i, errs[j], k] = sub_convolution[(syndrome[i]-k) % field]\n",
    "\n",
    "        # Step 2: pass error to check messages\n",
    "\n",
    "        error = np.zeros(n_errors, dtype=int)\n",
    "\n",
    "        for i in err_neighbourhood:\n",
    "            dets = err_neighbourhood[i]\n",
    "\n",
    "            # Isolate the relevant check messages\n",
    "            posterior = P[dets, i, :].copy()\n",
    "            # print(f'posterior: \\n {posterior}')\n",
    "\n",
    "            for j in range(len(dets)):\n",
    "                # Remove the j-th check message from the posterior\n",
    "                sub_posterior = np.delete(posterior, j, axis=0)\n",
    "\n",
    "                # Compute the product of probabilities\n",
    "                sub_posterior = np.prod(sub_posterior, axis=0) * prior[i, :]\n",
    "\n",
    "                #################################################\n",
    "                # WARNING: sub_posterior is no longer normalised!\n",
    "                #################################################\n",
    "\n",
    "                # Pass message\n",
    "                Q[i, dets[j], :] = sub_posterior / np.sum(sub_posterior)\n",
    "\n",
    "            # TODO: sub_posterior out of scope\n",
    "\n",
    "            # Step 3: calculate posterior and make hard decision on errors\n",
    "            posterior = np.prod(posterior, axis=0) * prior[i, :]\n",
    "            posterior_sum = np.sum(posterior)\n",
    "            for j in range(len(posterior)):\n",
    "                posterior[j] = posterior[j] / (posterior_sum - posterior[j])  ####### do I have blowing up problems here??? yes, yes you do...\n",
    "                posteriors[i, :] = posterior  ############### does OSD want the likelihoods or the probabilities??? (I think likelihoods here)\n",
    "                if posterior[j] >= 1:\n",
    "                    error[i] = j\n",
    "\n",
    "                # TODO: posteriors[i, :] does not depend on j, error[i] is overwritten\n",
    "                    \n",
    "                    ##############################################\n",
    "                    # WARNING: may overwrite if there are 2 error types (eg X and X^2) that are likely (ONLY happens when eg likelihoods are (0, 1, 1) so doing > 1 instead of >= 1 would fix this)\n",
    "                    ##############################################\n",
    "\n",
    "        # Step 4: check convergence\n",
    "        if np.all(h_eff @ error % field == syndrome):\n",
    "            return error, True, True, posteriors\n",
    "\n",
    "    if bp_only:\n",
    "        return posteriors, False\n",
    "\n",
    "\n",
    "    # ------------------------OSD--------------------------------\n",
    "\n",
    "    m, n = h_eff.shape\n",
    "\n",
    "    ##################################################################################\n",
    "    # For qubits, do normal OSD (need to be careful with error powers for qudits *help*)\n",
    "    ##################################################################################\n",
    "\n",
    "    # Step 1: order the errors by likelihood\n",
    "    # Row index = error mechanism, column index = power, i.e. entry for mechanism (1, ..., field-1)\n",
    "    col_rank_perm = np.argsort(-np.delete(posteriors, 0, axis=1), axis=None)\n",
    "    col_rank_inv_perm = np.empty_like(col_rank_perm)\n",
    "    col_rank_inv_perm[col_rank_perm] = np.arange(len(col_rank_perm))\n",
    "\n",
    "    # Step 2: create Galois field elements\n",
    "    GF = galois.GF(field)\n",
    "    H_gf = GF(h_eff.copy())\n",
    "    syndrome_gf = GF(syndrome.copy())\n",
    "\n",
    "    # Order the columns of h_gf and prior according to the ranking\n",
    "    H_ordered_gf = H_gf[:, col_rank_perm]\n",
    "    priors_perm = posteriors[col_rank_perm]\n",
    "\n",
    "    # Find the reduced row echelon form (RREF) and identify pivot columns\n",
    "    H_rref_gf, syndrome_rref_gf, pivot_cols = rref_with_pivots(H_ordered_gf, syndrome_gf)\n",
    "    m_ind = H_rref_gf.shape[0]\n",
    "    non_pivot_cols = [i for i in range(n) if i not in pivot_cols]\n",
    "\n",
    "    # Select the first rank(h_gf) linearly independent columns as basis set in P, others in B\n",
    "    P = H_rref_gf[:, pivot_cols]\n",
    "    assert P.shape == (m_ind, m_ind)\n",
    "    B = H_rref_gf[:, non_pivot_cols]\n",
    "\n",
    "    def sln_from(g):\n",
    "        assert g.shape == (n - m_ind,)\n",
    "        remainder =  syndrome_rref_gf - B @ g\n",
    "        fix = np.linalg.solve(P, remainder)\n",
    "        assert (P @ fix + B @ g == syndrome_rref_gf).all()\n",
    "\n",
    "        score = 0\n",
    "        sln = GF.Zeros(n)\n",
    "        # Find prob of basis set\n",
    "        for i in range(m_ind):\n",
    "            p = priors_perm[pivot_cols[i], fix[i]]\n",
    "            sln[pivot_cols[i]] = fix[i]\n",
    "            if p > 0:\n",
    "                score += np.log(p)\n",
    "            else:\n",
    "                score -= 1000\n",
    "        \n",
    "        for i in range(n - m_ind):\n",
    "            p = priors_perm[non_pivot_cols[i], g[i]]\n",
    "            sln[non_pivot_cols[i]] = g[i]\n",
    "            if p > 0:\n",
    "                score += np.log(p)\n",
    "            else:\n",
    "                score -= 1000\n",
    "\n",
    "        # Check sln makes correct syndrome\n",
    "        assert (H_rref_gf @ sln == syndrome_rref_gf).all()\n",
    "        assert (H_gf @ sln[col_rank_inv_perm] == syndrome_gf).all()\n",
    "\n",
    "        assert ((h_eff @ sln[col_rank_inv_perm].__array__()) % field == syndrome).all()\n",
    "\n",
    "        return np.array(sln[col_rank_inv_perm]), score\n",
    "\n",
    "    # OSD_0 solution\n",
    "    best_solution, best_score = sln_from(GF.Zeros(n - m_ind))\n",
    "    assert ((h_eff @ best_solution) % field == syndrome).all()\n",
    "    pivot_col_labels = {col_rank_perm[c]: np.delete(posteriors, 0, axis=1).reshape(-1)[col_rank_perm[c]] for c in pivot_cols}\n",
    "\n",
    "    # print(f'for debugging: {best_solution}, {True}, {[col_rank_perm[i] for i in pivot_cols]}, {pivot_col_labels}')\n",
    "\n",
    "    return best_solution, True, False, posteriors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bivariate Bicycle code for\n",
      "a(x, y) = 1x^0y^0 + 0x^0y^1 + 1x^1y^0 + 0x^1y^1\n",
      "b(x, y) = 1x^0y^0 + 1x^0y^1 + 0x^1y^0 + 0x^1y^1\n"
     ]
    }
   ],
   "source": [
    "# Testing...\n",
    "\n",
    "d = 5\n",
    "\n",
    "a = Polynomial(2, np.array([[1, 0], [-1, 0]]))\n",
    "b = Polynomial(2, np.array([[1, -1], [0, 0]]))\n",
    "bb = BivariateBicycle(a, b, d, d, 1)\n",
    "x_order = ['Idle', 0, 3, 1, 2]\n",
    "z_order = [0, 3, 1, 2, 'Idle']\n",
    "p = 0.002\n",
    "num_cycles = d\n",
    "error_rates = {'Meas': p, 'Prep': p, 'Idle': p, 'CNOT': p}\n",
    "max_iter = 100\n",
    "print(bb)\n",
    "\n",
    "qubits_dict, data_qubits, x_checks, z_checks = bb.qubits_dict, bb.data_qubits, bb.x_checks, bb.z_checks\n",
    "hx, hz = bb.hx, bb.hz\n",
    "lx, lz = bb.x_logicals, bb.z_logicals\n",
    "circ = construct_sm_circuit(bb, x_order, z_order)\n",
    "hx_eff, short_hx_eff, hz_eff, short_hz_eff, channel_prob_x, channel_prob_z, x_circuit, z_circuit = construct_decoding_matrix(bb, circ, error_rates, num_cycles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elean\\AppData\\Local\\Temp\\ipykernel_29108\\2162902609.py:98: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  P[i, errs[j], k] = sub_convolution[(syndrome[i]-k) % field]\n",
      "C:\\Users\\elean\\AppData\\Local\\Temp\\ipykernel_29108\\2162902609.py:129: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  posterior[j] = posterior[j] / (posterior_sum - posterior[j])  ####### do I have blowing up problems here??? yes, yes you do...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.006666666666666672"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d = 3\n",
    "# num_cycles = 3\n",
    "# p = 0.002\n",
    "\n",
    "res = simulate(bb, 50, circ, error_rates, num_cycles, hx_eff, short_hx_eff, hz_eff, short_hz_eff, channel_prob_x, channel_prob_z, max_iter, verbose=False)\n",
    "res / num_cycles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elean\\AppData\\Local\\Temp\\ipykernel_29108\\2162902609.py:98: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  P[i, errs[j], k] = sub_convolution[(syndrome[i]-k) % field]\n",
      "C:\\Users\\elean\\AppData\\Local\\Temp\\ipykernel_29108\\2162902609.py:129: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  posterior[j] = posterior[j] / (posterior_sum - posterior[j])  ####### do I have blowing up problems here??? yes, yes you do...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d = 5\n",
    "# num_cycles = 5\n",
    "# p = 0.002\n",
    "\n",
    "res = simulate(bb, 10, circ, error_rates, num_cycles, hx_eff, short_hx_eff, hz_eff, short_hz_eff, channel_prob_x, channel_prob_z, max_iter, verbose = False)\n",
    "res / num_cycles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d=3 per cycle\n",
    "\n",
    "0.06/3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d=5 per cycle\n",
    "\n",
    "0.12/5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prior = np.zeros((len(channel_prob_x), 2), dtype=float)\n",
    "\n",
    "for i, prob in enumerate(channel_prob_x):\n",
    "    x_prior[i, 0] = 1 - prob\n",
    "    for j in range(1, 2):\n",
    "        x_prior[i, j] = prob / (2 - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_neighbourhood = _err_to_det(short_hx_eff)\n",
    "det_neighbourhood = _det_to_err(short_hx_eff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bbq_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
